{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rmCPmqFL6hCQ"
   },
   "source": [
    "# üìä Dataset Maker by Hollowstrawberry\n",
    "\n",
    "This is based on the work of [Kohya-ss](https://github.com/kohya-ss/sd-scripts) and [Linaqruf](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb). Thank you!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚≠ï Disclaimer\n",
    "The purpose of this document is to research bleeding-edge technologies in the field of machine learning inference.  \n",
    "Please read and follow the [Google Colab guidelines](https://research.google.com/colaboratory/faq.html) and its [Terms of Service](https://research.google.com/colaboratory/tos_v3.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-rdgF2AWLS2h"
   },
   "source": [
    "| |GitHub|üá¨üáß English|üá™üá∏ Spanish|\n",
    "|:--|:-:|:-:|:-:|\n",
    "| üè† **Homepage** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab) | | |\n",
    "| üìä **Dataset Maker** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Dataset_Maker.ipynb) |\n",
    "| ‚≠ê **Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) |\n",
    "| üåü **XL Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb) |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cellView": "form",
    "id": "cBa7KdewQ4BU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /opt/conda/lib/python3.11/site-packages/setuptools-70.3.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.11/site-packages (8.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (8.22.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (5.14.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbbd81ffec34fbf822704b8dd8975e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h2>üö© Start Here</h2>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9370ee46226d495ab054ca845a2f2e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h2>1Ô∏è‚É£ Setup</h2>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3169d233394e608f37d4ead888cbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='This cell will load some requirements and create the necessary folders in your Google Drive.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61e5a5422ef41b5b0015bfd3ae33963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value=\"Your project name can't contain spaces but it can contain a single / to make a subfolder in your ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca772f9dff54f4a8d393728cda7b831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Project name:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a907c536e1e049a9a96a145014f7d72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value=\"The folder structure doesn't matter and is purely for comfort. Make sure to always pick the same ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55cf0af7ddb44feaad168d242e39995c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Folder structure:', index=1, options=('Organize by category (MyDrive/lora_training/datas‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e163772ec98c429f8f3a9cf96e66c2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Proceed', icon='check', style=ButtonStyle(), tooltip='Proceed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install ipywidgets\n",
    "\n",
    "import os\n",
    "from IPython import get_ipython\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import pathlib\n",
    "\n",
    "COLAB = False\n",
    "\n",
    "if COLAB:\n",
    "    from google.colab.output import clear as clear_output\n",
    "else:\n",
    "    from IPython.display import clear_output\n",
    "\n",
    "display(\n",
    "    widgets.HTML(\"<h2>üö© Start Here</h2>\"),\n",
    ")\n",
    "\n",
    "project_name_widget = widgets.Text(description='Project name:')\n",
    "folder_structure_widget = widgets.Dropdown(\n",
    "    options=[\n",
    "        \"Organize by category (MyDrive/lora_training/datasets/project_name)\",\n",
    "        \"Organize by project (MyDrive/Loras/project_name/dataset)\"\n",
    "    ],\n",
    "    value=\"Organize by project (MyDrive/Loras/project_name/dataset)\",\n",
    "    description='Folder structure:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def proceed_step_1(b):\n",
    "    global project_name\n",
    "    project_name = project_name_widget.value\n",
    "    project_name = project_name.strip()\n",
    "\n",
    "    global folder_structure\n",
    "    folder_structure = folder_structure_widget.value\n",
    "\n",
    "    global project_base\n",
    "    global project_subfolder\n",
    "    global root_dir\n",
    "    global deps_dir\n",
    "    global main_dir\n",
    "    global config_folder\n",
    "    global images_folder\n",
    "    global step1_installed_flag\n",
    "\n",
    "    if not project_name or any(c in project_name for c in \" .()\\\"'\\\\\") or project_name.count(\"/\") > 1:\n",
    "        print(\"Please write a valid project_name.\")\n",
    "    else:\n",
    "        if COLAB and not os.path.exists('/content/drive'):\n",
    "            from google.colab import drive\n",
    "            print(\"üìÇ Connecting to Google Drive...\")\n",
    "            drive.mount('/content/drive')\n",
    "\n",
    "        project_base = project_name if \"/\" not in project_name else project_name[:project_name.rfind(\n",
    "            \"/\")]\n",
    "        project_subfolder = project_name if \"/\" not in project_name else project_name[project_name.rfind(\n",
    "            \"/\")+1:]\n",
    "\n",
    "        root_dir = \"/content\" if COLAB else pathlib.Path.home() / \"Loras\"\n",
    "        deps_dir = os.path.join(root_dir, \"deps\")\n",
    "\n",
    "        if \"/Loras\" in folder_structure:\n",
    "            main_dir = os.path.join(\n",
    "                root_dir, \"drive/MyDrive/Loras\") if COLAB else root_dir\n",
    "            config_folder = os.path.join(main_dir, project_base)\n",
    "            images_folder = os.path.join(main_dir, project_base, \"dataset\")\n",
    "            if \"/\" in project_name:\n",
    "                images_folder = os.path.join(images_folder, project_subfolder)\n",
    "        else:\n",
    "            main_dir = os.path.join(\n",
    "                root_dir, \"drive/MyDrive/lora_training\") if COLAB else root_dir\n",
    "            config_folder = os.path.join(main_dir, \"config\", project_name)\n",
    "            images_folder = os.path.join(main_dir, \"datasets\", project_name)\n",
    "\n",
    "        for dir in [main_dir, deps_dir, images_folder, config_folder]:\n",
    "            os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "        print(f\"‚úÖ Project {project_name} is ready!\")\n",
    "        step1_installed_flag = True\n",
    "\n",
    "\n",
    "proceed1_btn = widgets.Button(\n",
    "    description='Proceed',\n",
    "    disabled=False,\n",
    "    button_style='',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Proceed',\n",
    "    icon='check'  # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "proceed1_btn.on_click(proceed_step_1)\n",
    "\n",
    "display(\n",
    "    widgets.HTML(\"<h2>1Ô∏è‚É£ Setup</h2>\"),\n",
    "    widgets.Label(\n",
    "        \"This cell will load some requirements and create the necessary folders in your Google Drive.\"),\n",
    "    widgets.Label(\n",
    "        \"Your project name can't contain spaces but it can contain a single / to make a subfolder in your dataset.\"),\n",
    "    project_name_widget,\n",
    "    widgets.Label(\n",
    "        \"The folder structure doesn't matter and is purely for comfort. Make sure to always pick the same one. I like organizing by project.\"),\n",
    "    folder_structure_widget,\n",
    "    proceed1_btn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cellView": "form",
    "id": "afu5dCKTV31E"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9bdb2d8ff4404ab2a5b614a9887deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"\\n    <h2>2Ô∏è‚É£ Scrape images from Gelbooru</h2>\\n    <p>We will grab images from the popular anime ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf6fb3793c04a1faf4f0e290a39dc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Separate words with underscores, separate tags with spaces, and use - to exclude a tag. You can a‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d58050206542f3bb17502d8d520eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='tags')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44523c18680a459aac2a425a01450fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='If an image is bigger than this resolution a smaller version will be downloaded instead.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45e747e8bdd4603bf2a389a326f2383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=3072, description='Max resolution:', max=8196, min=1024, step=1024)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa54612f447346cba191b70fc5c5e642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Proceed', icon='check', style=ButtonStyle(), tooltip='Proceed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "display(widgets.HTML('''\n",
    "    <h2>2Ô∏è‚É£ Scrape images from Gelbooru</h2>\n",
    "    <p>We will grab images from the popular anime gallery <a href='https://gelbooru.com/'>Gelbooru</a>. Images are sorted by tags, including poses, scenes, character traits, character names, artists, etc.</p>\n",
    "    <ul>\n",
    "        <li>If you instead want to use your own images, upload them to your Google Drive's `Loras/project_name/dataset` folder.</li>\n",
    "        <li>If you instead want to download screencaps of anime episodes, try <a href='https://colab.research.google.com/drive/1oBSntB40BKzNmKceXUlkXzujzdQw-Ci7'>this other colab by another person</a>. It's more complicated though.</li>\n",
    "    </ul>\n",
    "    <p>Up to 1000 images may be downloaded by this step in just one minute. Don't abuse it.</p>\n",
    "    <p>Your target tags should include the relevant tags for your character/concept/artstyle, and exclude undesired tags (for example, explicit images may affect learning).</p>\n",
    "'''))\n",
    "\n",
    "tags_widget = widgets.Text(description=\"tags\")\n",
    "max_resolution_widget = widgets.BoundedIntText(\n",
    "    value=3072,\n",
    "    min=1024,\n",
    "    max=8196,\n",
    "    step=1024,\n",
    "    description='Max resolution:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "include_posts_with_parent_widget = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Include posts with parent:',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "def proceed_step_2(b):\n",
    "    if \"step1_installed_flag\" not in globals():\n",
    "        raise Exception(\"Please run step 1 first!\")\n",
    "\n",
    "    global tags\n",
    "    tags = tags_widget.value\n",
    "    global max_resolution\n",
    "    max_resolution = 3072\n",
    "\n",
    "    global include_posts_with_parent\n",
    "    include_posts_with_parent = include_posts_with_parent_widget.value\n",
    "\n",
    "    global step2_installed_flag\n",
    "\n",
    "    tags = tags.replace(\" \", \"+\")\\\n",
    "            .replace(\"(\", \"%28\")\\\n",
    "            .replace(\")\", \"%29\")\\\n",
    "            .replace(\":\", \"%3a\")\\\n",
    "            .replace(\"&\", \"%26\")\\\n",
    "          \n",
    "    url = \"https://gelbooru.com/index.php?page=dapi&json=1&s=post&q=index&limit=100&tags={}\".format(tags)\n",
    "    user_agent = \"Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko; compatible; Googlebot/2.1; +http://www.google.com/bot.html) Chrome/93.0.4577.83 Safari/537.36\"\n",
    "    limit = 100 # hardcoded by gelbooru\n",
    "    total_limit = 1000 # you can edit this if you want but I wouldn't recommend it\n",
    "    supported_types = (\".png\", \".jpg\", \".jpeg\")\n",
    "\n",
    "    def ubuntu_deps():\n",
    "        print(\"üè≠ Installing dependencies...\\n\")\n",
    "        !apt -y install aria2\n",
    "        return not get_ipython().__dict__['user_ns']['_exit_code']\n",
    "\n",
    "    if \"step2_installed_flag\" not in globals():\n",
    "        if ubuntu_deps():\n",
    "            clear_output()\n",
    "            step2_installed_flag = True\n",
    "        else:\n",
    "            print(\"‚ùå Error installing dependencies, attempting to continue anyway...\")\n",
    "\n",
    "    def get_json(url):\n",
    "        with urlopen(Request(url, headers={\"User-Agent\": user_agent})) as page:\n",
    "            return json.load(page)\n",
    "\n",
    "    def filter_images(data):\n",
    "        return [p[\"file_url\"] if p[\"width\"]*p[\"height\"] <= max_resolution**2 else p[\"sample_url\"]\n",
    "                for p in data[\"post\"]\n",
    "                if (p[\"parent_id\"] == 0 or include_posts_with_parent)\n",
    "                and p[\"file_url\"].lower().endswith(supported_types)]\n",
    "    \n",
    "    global count\n",
    "\n",
    "    def download_images():\n",
    "        data = get_json(url)\n",
    "        count = data[\"@attributes\"][\"count\"]\n",
    "\n",
    "        if count == 0:\n",
    "            print(\"üì∑ No results found\")\n",
    "            return\n",
    "\n",
    "        print(f\"üéØ Found {count} results\")\n",
    "        test_url = \"https://gelbooru.com/index.php?page=post&s=list&tags={}\".format(tags)\n",
    "        display(Markdown(f\"[Click here to open in browser!]({test_url})\"))\n",
    "\n",
    "        perform_download_btn = widgets.Button(\n",
    "            description='Yes',\n",
    "            disabled=False,\n",
    "            button_style='',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltip='Yes',\n",
    "            icon='check'  # (FontAwesome names without the `fa-` prefix)\n",
    "        )\n",
    "\n",
    "        cancel_dowload_btn = widgets.Button(\n",
    "            description='No',\n",
    "            disabled=False,\n",
    "            button_style='',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltip='No',\n",
    "            icon='check'  # (FontAwesome names without the `fa-` prefix)\n",
    "        )\n",
    "\n",
    "        def perform_download(b): \n",
    "            print(\"üì© Grabbing image list...\")\n",
    "\n",
    "            data = get_json(url)\n",
    "            count = data[\"@attributes\"][\"count\"]\n",
    "\n",
    "            image_urls = set()\n",
    "            image_urls = image_urls.union(filter_images(data))\n",
    "            for i in range(total_limit // limit):\n",
    "                count -= limit\n",
    "                if count <= 0:\n",
    "                    break\n",
    "                time.sleep(0.1)\n",
    "                image_urls = image_urls.union(filter_images(get_json(url+f\"&pid={i+1}\")))\n",
    "\n",
    "            scrape_file = os.path.join(config_folder, f\"scrape_{project_subfolder}.txt\")\n",
    "            with open(scrape_file, \"w\") as f:\n",
    "                f.write(\"\\n\".join(image_urls))\n",
    "\n",
    "            print(f\"üåê Saved links to {scrape_file}\\n\\nüîÅ Downloading images...\\n\")\n",
    "            old_img_count = len([f for f in os.listdir(images_folder) if f.lower().endswith(supported_types)])\n",
    "\n",
    "            os.chdir(images_folder)\n",
    "            !aria2c --console-log-level=warn -c -x 16 -k \"1M\" -s 16 -i {scrape_file}\n",
    "\n",
    "            new_img_count = len([f for f in os.listdir(images_folder) if f.lower().endswith(supported_types)])\n",
    "            print(f\"\\n‚úÖ Downloaded {new_img_count - old_img_count} images.\")\n",
    "\n",
    "        perform_download_btn.on_click(perform_download)\n",
    "        cancel_dowload_btn.on_click(lambda: display(widgets.Markdown(\"‚ùå Download cancelled\")))\n",
    "\n",
    "        display(\n",
    "            widgets.Label (f\"üîΩ Will download to {images_folder.replace('/content/drive/', '')} (A confirmation box should appear below, otherwise run this cell again)\"),\n",
    "            widgets.Label(\"‚ùì Enter the word 'yes' if you want to proceed with the download: \"),\n",
    "            perform_download_btn, \n",
    "            cancel_dowload_btn\n",
    "        )\n",
    "\n",
    "    download_images()\n",
    "\n",
    "proceed2_btn = widgets.Button(\n",
    "    description='Proceed',\n",
    "    disabled=False,\n",
    "    button_style='',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Proceed',\n",
    "    icon='check'  # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "proceed2_btn.on_click(proceed_step_2)\n",
    "\n",
    "display(\n",
    "    widgets.Label('''Separate words with underscores, separate tags with spaces, and use - to exclude a tag. You can also include a minimum score: `score:>10`'''),\n",
    "    tags_widget,\n",
    "    widgets.Label('If an image is bigger than this resolution a smaller version will be downloaded instead.'),\n",
    "    max_resolution_widget,\n",
    "    proceed2_btn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cellView": "form",
    "id": "b218DEEMpwzB"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876f7f619c904c0d8c7fdb832f724cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h2>3Ô∏è‚É£ Curate your images</h2>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1933b31fee543b181885b5c806ca4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='We will find duplicate images with the FiftyOne AI, and mark them with `delete`.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71210d5f8cd04972806774e59ddcb9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value=\"Then, an interactive area will appear below this cell that lets you visualize all your images and‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3cb06f0b8e64a7bbf93548afbc1db65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='If the interactive area appears blank for over a minute, try enabling cookies and removing tracki‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c57a0a8cb354566be483f35037f7968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Regardless, you can save your changes by sending Enter in the input box above the interactive are‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abeacb3625f347feba35fea1a077831e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='This is how similar 2 images must be to be marked for deletion. I recommend 0.97 to 0.99:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0b2afa0e234ad6b4bf73562b0a217b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.0003, description='Similarity threshold:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10f33242df54d2fb9e86878c2569df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Proceed', icon='check', style=ButtonStyle(), tooltip='Proceed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarity_threshold_widget = widgets.FloatText(\n",
    "    value=3e-4,\n",
    "    description='Similarity threshold:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def proceed_step_3(b):\n",
    "    if \"step1_installed_flag\" not in globals():\n",
    "        raise Exception(\"Please run step 1 first!\")\n",
    "\n",
    "    return\n",
    "    \n",
    "    similarity_threshold = similarity_threshold_widget.value\n",
    "    os.chdir(root_dir)\n",
    "    model_name = \"clip-vit-base32-torch\"\n",
    "    supported_types = (\".png\", \".jpg\", \".jpeg\")\n",
    "    img_count = len(os.listdir(images_folder))\n",
    "    batch_size = min(250, img_count)\n",
    "\n",
    "    if \"step3_installed_flag\" not in globals():\n",
    "        print(\"üè≠ Installing dependencies...\\n\")\n",
    "        %pip -q install fiftyone ftfy\n",
    "        %pip -q install fiftyone-db-ubuntu2204\n",
    "        if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
    "            clear_output()\n",
    "            step3_installed_flag = True\n",
    "        else:\n",
    "            print(\"‚ùå Error installing dependencies, attempting to continue anyway...\")\n",
    "\n",
    "    import numpy as np\n",
    "    import fiftyone as fo\n",
    "    import fiftyone.zoo as foz\n",
    "    from fiftyone import ViewField as F\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "    non_images = [f for f in os.listdir(images_folder) if not f.lower().endswith(supported_types)]\n",
    "    if non_images:\n",
    "        print(f\"üí• Error: Found non-image file {non_images[0]} - This program doesn't allow it. Sorry! Use the Extras at the bottom to clean the folder.\")\n",
    "    elif img_count == 0:\n",
    "        print(f\"üí• Error: No images found in {images_folder}\")\n",
    "    else:\n",
    "        print(\"\\nüíø Analyzing dataset...\\n\")\n",
    "        dataset = fo.Dataset.from_dir(images_folder, dataset_type=fo.types.ImageDirectory)\n",
    "        model = foz.load_zoo_model(model_name)\n",
    "        embeddings = dataset.compute_embeddings(model, batch_size=batch_size)\n",
    "\n",
    "        batch_embeddings = np.array_split(embeddings, batch_size)\n",
    "        similarity_matrices = []\n",
    "        max_size_x = max(array.shape[0] for array in batch_embeddings)\n",
    "        max_size_y = max(array.shape[1] for array in batch_embeddings)\n",
    "\n",
    "        for i, batch_embedding in enumerate(batch_embeddings):\n",
    "            similarity = cosine_similarity(batch_embedding)\n",
    "            #Pad 0 for np.concatenate\n",
    "            padded_array = np.zeros((max_size_x, max_size_y))\n",
    "            padded_array[0:similarity.shape[0], 0:similarity.shape[1]] = similarity\n",
    "            similarity_matrices.append(padded_array)\n",
    "\n",
    "        similarity_matrix = np.concatenate(similarity_matrices, axis=0)\n",
    "        similarity_matrix = similarity_matrix[0:embeddings.shape[0], 0:embeddings.shape[0]]\n",
    "\n",
    "        similarity_matrix = cosine_similarity(embeddings)\n",
    "        similarity_matrix -= np.identity(len(similarity_matrix))\n",
    "\n",
    "        dataset.match(F(\"max_similarity\") > similarity_threshold)\n",
    "        dataset.tags = [\"delete\", \"has_duplicates\"]\n",
    "\n",
    "        id_map = [s.id for s in dataset.select_fields([\"id\"])]\n",
    "        samples_to_remove = set()\n",
    "        samples_to_keep = set()\n",
    "\n",
    "        for idx, sample in enumerate(dataset):\n",
    "            if sample.id not in samples_to_remove:\n",
    "            # Keep the first instance of two duplicates\n",
    "                samples_to_keep.add(sample.id)\n",
    "        \n",
    "            dup_idxs = np.where(similarity_matrix[idx] > similarity_threshold)[0]\n",
    "            for dup in dup_idxs:\n",
    "                # We kept the first instance so remove all other duplicates\n",
    "                samples_to_remove.add(id_map[dup])\n",
    "\n",
    "            if len(dup_idxs) > 0:\n",
    "                sample.tags.append(\"has_duplicates\")\n",
    "                sample.save()\n",
    "            else:\n",
    "                sample.tags.append(\"delete\")\n",
    "                sample.save()\n",
    "\n",
    "        clear_output()\n",
    "\n",
    "        sidebar_groups = fo.DatasetAppConfig.default_sidebar_groups(dataset)\n",
    "        for group in sidebar_groups[1:]:\n",
    "            group.expanded = False\n",
    "            dataset.app_config.sidebar_groups = sidebar_groups\n",
    "            dataset.save()\n",
    "            session = fo.launch_app(dataset)\n",
    "\n",
    "        print(\"‚ùó Wait a minute for the session to load. If it doesn't, read above.\")\n",
    "        print(\"‚ùó When it's ready, you'll see a grid of your images.\")\n",
    "        print(\"‚ùó On the left side enable \\\"sample tags\\\" to visualize the images marked for deletion.\")\n",
    "        print(\"‚ùó You can mark your own images with the \\\"delete\\\" label by selecting them and pressing the tag icon at the top.\")\n",
    "        input(\"‚≠ï When you're done, enter something here to save your changes: \")\n",
    "\n",
    "        print(\"üíæ Saving...\")\n",
    "\n",
    "        marked = [s for s in dataset if \"delete\" in s.tags]\n",
    "        dataset.remove_samples(marked)\n",
    "        previous_folder = images_folder[:images_folder.rfind(\"/\")]\n",
    "        dataset.export(export_dir=os.path.join(images_folder, project_subfolder), dataset_type=fo.types.ImageDirectory)\n",
    "        \n",
    "        temp_suffix = \"_temp\"\n",
    "        !mv {images_folder} {images_folder}{temp_suffix}\n",
    "        !mv {images_folder}{temp_suffix}/{project_subfolder} {images_folder}\n",
    "        !rm -r {images_folder}{temp_suffix}\n",
    "\n",
    "        session.refresh()\n",
    "        fo.close_app()\n",
    "        clear_output()\n",
    "\n",
    "        print(f\"\\n‚úÖ Removed {len(marked)} images from dataset. You now have {len(os.listdir(images_folder))} images.\")\n",
    "\n",
    "proceed3_btn = widgets.Button(\n",
    "    description='Proceed',\n",
    "    disabled=False,\n",
    "    button_style='',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Proceed',\n",
    "    icon='check'  # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "proceed3_btn.on_click(proceed_step_3)\n",
    "\n",
    "display(\n",
    "    widgets.HTML(\"<h2>3Ô∏è‚É£ Curate your images</h2>\"),\n",
    "    widgets.Label(\"We will find duplicate images with the FiftyOne AI, and mark them with `delete`.\"),\n",
    "    widgets.Label(\"Then, an interactive area will appear below this cell that lets you visualize all your images and manually mark with `delete` to the ones you don't like.\"),\n",
    "    widgets.Label(\"If the interactive area appears blank for over a minute, try enabling cookies and removing tracking protection for the Google Colab website, as they may break it.\"),\n",
    "    widgets.Label(\"Regardless, you can save your changes by sending Enter in the input box above the interactive area.\"),\n",
    "    widgets.Label(\"This is how similar 2 images must be to be marked for deletion. I recommend 0.97 to 0.99:\"),\n",
    "    similarity_threshold_widget,\n",
    "    proceed3_btn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /opt/conda/lib/python3.11/site-packages/setuptools-70.3.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: spandrel in /opt/conda/lib/python3.11/site-packages (0.3.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (4.66.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from spandrel) (2.2.2+cu121)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (from spandrel) (0.17.2+cu121)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from spandrel) (0.4.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from spandrel) (1.26.4)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.11/site-packages (from spandrel) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from spandrel) (4.11.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (3.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.11/site-packages (from torch->spandrel) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->spandrel) (12.4.127)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision->spandrel) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->spandrel) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->spandrel) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61dbe948e8cf4b29a84d55ee33bade7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h2>4Ô∏è‚É£ Upscale images.</h2>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7130e638eb45668a556139bbba5768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Upscale model:', options=('2x-sudo-RealESRGAN.pth',), value='2x-sudo-RealESRGAN.pth')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71300b76063049c38bab804e4eb66b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Proceed', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install spandrel tqdm\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from spandrel import ModelLoader, ImageModelDescriptor\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "upscale_model_path = Path(main_dir)/ \"upscale_models\"\n",
    "upscale_models = [p.name for p in upscale_model_path.iterdir()]\n",
    "upscale_model_widget = widgets.Dropdown(\n",
    "    options=upscale_models,\n",
    "    value=upscale_models[0],\n",
    "    description='Upscale model:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def image_to_tensor(img: np.ndarray) -> torch.Tensor:\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    if img.ndim == 2:\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "    if img.shape[2] == 1:\n",
    "        pass\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    tensor = torch.from_numpy(img)\n",
    "    return tensor.unsqueeze(0).cuda()\n",
    "\n",
    "\n",
    "def tensor_to_image(tensor: torch.Tensor) -> np.ndarray:\n",
    "    image = tensor.cpu().squeeze().numpy()\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    image = np.clip((image * 255.0).round(), 0, 255)\n",
    "    image = image.astype(np.uint8)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image\n",
    "\n",
    "def perform_resize(b):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = ModelLoader().load_from_file(upscale_model_path / upscale_model_widget.value)\n",
    "\n",
    "    if not isinstance(model, ImageModelDescriptor):\n",
    "        print(\"invalid model\")\n",
    "        return\n",
    "\n",
    "    print(\n",
    "        model.scale,\n",
    "        model.input_channels,\n",
    "        model.output_channels,\n",
    "        model.tags,\n",
    "        model.tiling,\n",
    "    )\n",
    "\n",
    "    model.cuda()\n",
    "\n",
    "    input = Path(config_folder) / \"orig\"\n",
    "    output = Path(config_folder) / \"dataset\"\n",
    "\n",
    "    if not input.exists() and output.exists():\n",
    "        print(\n",
    "            \"'orig' path does not exists, but 'dataset' exists. rename 'dataset' to 'orig'.\"\n",
    "        )\n",
    "        shutil.move(output, input)\n",
    "\n",
    "    elif not input.exists:\n",
    "        print(\"'orig' directory not found. Abort.\")\n",
    "        return\n",
    "\n",
    "    if not output.exists():\n",
    "        output.mkdir()\n",
    "\n",
    "    paths = [p for p in input.iterdir()]\n",
    "\n",
    "    for i in tqdm(paths):\n",
    "        rel = i.relative_to(input)\n",
    "        o = output / rel\n",
    "\n",
    "        if i.is_dir():\n",
    "            o.mkdir()\n",
    "\n",
    "            continue\n",
    "\n",
    "        # print(i)\n",
    "        img = cv2.imread(i, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        if img is None:\n",
    "            continue\n",
    "            \n",
    "        img_tensor = image_to_tensor(img)\n",
    "        img_tensor.to(device)\n",
    "\n",
    "        out_tensor = model(img_tensor)\n",
    "        out = tensor_to_image(out_tensor)\n",
    "\n",
    "        cv2.imwrite(o, out)\n",
    "\n",
    "    print(\"image upscale complete.\")\n",
    "    \n",
    "proceed_resize = widgets.Button(\n",
    "    description = \"Proceed\"\n",
    ")\n",
    "\n",
    "proceed_resize.on_click(perform_resize)\n",
    "\n",
    "display(\n",
    "    widgets.HTML(\"<h2>4Ô∏è‚É£ Upscale images.</h2>\"),\n",
    "    upscale_model_widget,\n",
    "    proceed_resize\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cellView": "form",
    "id": "sl4FD7Mz-uea"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499c79f5850b4fa88f2e3c08a41ce472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h2>4Ô∏è‚É£ Tag your images</h2>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3435522f5f0b4c20a537b3ebf9f243d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<p>We will be using AI to automatically tag your images, specifically \\n        <a href='https://h‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c7f1923d0740b0951dff0de2892a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Giving tags/captions to your images allows for much better training. \\n        This process shoul‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd8c2b5b0a54c5d97c6b07d60fc4d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Method', options=('Anime tags', 'Photo captions'), value='Anime tags')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6b16c51ce24d7e9982e7203da0b572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>Anime:</b> The threshold is the minimum level of confidence the tagger must have \\n      in ord‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162f3d3bfbb74e9195b4cd0f43489c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedFloatText(value=0.35, description='Tag threshold:', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0171053bd0d2417ab1e307e68bddbbb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='bangs, breasts, multicolored hair, two-tone hair, gradient hair, virtual youtuber, parody, sty‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b1e56c1da3443a9e9d58b2466037a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>Photos:</b> The minimum and maximum length of tokens/words in each caption.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1ce415edee40e79bc7559999bf9911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=10, description='Caption min:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ed2cf896d64ab989b03250885f72e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=75, description='Caption min:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2992d8864b4f7facb511cebed34930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Proceed', icon='check', style=ButtonStyle(), tooltip='Proceed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "method_widget = widgets.Dropdown(\n",
    "    value=\"Anime tags\", options=[\"Anime tags\", \"Photo captions\"], description=\"Method\"\n",
    ")\n",
    "\n",
    "tag_threshold_widget = widgets.BoundedFloatText(\n",
    "    value=0.35, min=0.0, max=1.0, step=0.01, description=\"Tag threshold:\"\n",
    ")\n",
    "\n",
    "blacklist_tags_widget = widgets.Textarea(\n",
    "    value=\"bangs, breasts, multicolored hair, two-tone hair, gradient hair, virtual youtuber, parody, style parody, official alternate costume, official alternate hairstyle, official alternate hair length, alternate costume, alternate hairstyle, alternate hair length, alternate hair color\",\n",
    "    description=\"Blacklist tags:\",\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "caption_min_widget = widgets.IntText(\n",
    "    value=10, description=\"Caption min:\", disabled=False\n",
    ")\n",
    "\n",
    "caption_max_widget = widgets.IntText(\n",
    "    value=75, description=\"Caption min:\", disabled=False\n",
    ")\n",
    "\n",
    "proceed4_btn = widgets.Button(\n",
    "    description=\"Proceed\",\n",
    "    disabled=False,\n",
    "    button_style=\"\",  # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip=\"Proceed\",\n",
    "    icon=\"check\",  # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "display(\n",
    "    widgets.HTML(\"<h2>4Ô∏è‚É£ Tag your images</h2>\"),\n",
    "    widgets.HTML(\n",
    "        \"\"\"<p>We will be using AI to automatically tag your images, specifically \n",
    "        <a href='https://huggingface.co/SmilingWolf/wd-v1-4-swinv2-tagger-v2'>Waifu Diffusion</a> \n",
    "        in the case of anime and <a href='https://huggingface.co/spaces/Salesforce/BLIP'>BLIP</a> \n",
    "        in the case of photos.</p>\n",
    "    \"\"\"\n",
    "    ),\n",
    "    widgets.Label(\n",
    "        \"\"\"Giving tags/captions to your images allows for much better training. \n",
    "        This process should take a couple minutes.\"\"\"\n",
    "    ),\n",
    "    method_widget,\n",
    "    widgets.HTML(\n",
    "        \"\"\"<b>Anime:</b> The threshold is the minimum level of confidence the tagger must have \n",
    "      in order to include a tag. Lower threshold = More tags. Recommended 0.35 to 0.5\n",
    "    \"\"\"\n",
    "    ),\n",
    "    tag_threshold_widget,\n",
    "    blacklist_tags_widget,\n",
    "    widgets.HTML(\n",
    "        \"\"\"<b>Photos:</b> The minimum and maximum length of tokens/words in each caption.\"\"\"\n",
    "    ),\n",
    "    caption_min_widget,\n",
    "    caption_max_widget,\n",
    "    proceed4_btn,\n",
    ")\n",
    "\n",
    "def proceed_step_4(b):\n",
    "    if \"step1_installed_flag\" not in globals():\n",
    "        raise Exception(\"Please run step 1 first!\")\n",
    "\n",
    "    method = method_widget.value\n",
    "    tag_threshold = tag_threshold_widget.value\n",
    "    blacklist_tags = blacklist_tags_widget.value\n",
    "    caption_min = caption_min_widget.value\n",
    "    caption_max = caption_max_widget.value\n",
    "\n",
    "    # %env PYTHONPATH=/env/python\n",
    "    os.chdir(root_dir)\n",
    "    kohya = os.path.join(root_dir, \"sd-scripts\")\n",
    "    if not os.path.exists(kohya):\n",
    "        !git clone https://github.com/kohya-ss/sd-scripts {kohya}\n",
    "    os.chdir(kohya)\n",
    "    !git checkout tags/v0.8.7\n",
    "    !git reset --hard\n",
    "    !pip install -r requirements.txt\n",
    "    os.chdir(root_dir)\n",
    "\n",
    "    if \"tags\" in method:\n",
    "        if \"step4a_installed_flag\" not in globals():\n",
    "            print(\"\\nüè≠ Installing dependencies...\\n\")\n",
    "            if not get_ipython().__dict__[\"user_ns\"][\"_exit_code\"]:\n",
    "                clear_output()\n",
    "                step4a_installed_flag = True\n",
    "            else:\n",
    "                print(\"‚ùå Error installing dependencies, trying to continue anyway...\")\n",
    "\n",
    "        print(\"\\nüö∂‚Äç‚ôÇÔ∏è Launching program...\\n\")\n",
    "\n",
    "        os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "        # %env PYTHONPATH={kohya}\n",
    "        !python -i {kohya}/finetune/tag_images_by_wd14_tagger.py \\\n",
    "            --onnx \\\n",
    "            --repo_id=SmilingWolf/wd-swinv2-tagger-v3 \\\n",
    "            --model_dir={root_dir} \\\n",
    "            --thresh={tag_threshold} \\\n",
    "            --batch_size=8 \\\n",
    "            --caption_extension=.txt \\\n",
    "            --force_download \\\n",
    "            {images_folder} \\\n",
    "\n",
    "        if not get_ipython().__dict__[\"user_ns\"][\"_exit_code\"]:\n",
    "            print(\"removing underscores and blacklist...\")\n",
    "            blacklisted_tags = [t.strip() for t in blacklist_tags.split(\",\")]\n",
    "            from collections import Counter\n",
    "\n",
    "            top_tags = Counter()\n",
    "            for txt in [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]:\n",
    "                with open(os.path.join(images_folder, txt), \"r\") as f:\n",
    "                    tags = [t.strip() for t in f.read().split(\",\")]\n",
    "                    tags = [t.replace(\"_\", \" \") if len(t) > 3 else t for t in tags]\n",
    "                    tags = [t for t in tags if t not in blacklisted_tags]\n",
    "                top_tags.update(tags)\n",
    "                with open(os.path.join(images_folder, txt), \"w\") as f:\n",
    "                    f.write(\", \".join(tags))\n",
    "\n",
    "            # %env PYTHONPATH=/env/python\n",
    "            # clear_output()\n",
    "            print(f\"üìä Tagging complete. Here are the top 50 tags in your dataset:\")\n",
    "            print(\"\\n\".join(f\"{k} ({v})\" for k, v in top_tags.most_common(50)))\n",
    "\n",
    "\n",
    "    else:  # Photos\n",
    "        if \"step4b_installed_flag\" not in globals():\n",
    "            print(\"\\nüè≠ Installing dependencies...\\n\")\n",
    "            \n",
    "            if not get_ipython().__dict__[\"user_ns\"][\"_exit_code\"]:\n",
    "                # clear_output()\n",
    "                step4b_installed_flag = True\n",
    "            else:\n",
    "                print(\"‚ùå Error installing dependencies, trying to continue anyway...\")\n",
    "\n",
    "        display(\"\\nüö∂‚Äç‚ôÇÔ∏è Launching program...\\n\")\n",
    "\n",
    "        os.chdir(kohya)\n",
    "        print(f\"{images_folder}\")\n",
    "        # %env PYTHONPATH={kohya}\n",
    "        !python -i {kohya}/finetune/make_captions.py \\\n",
    "            {images_folder} \\\n",
    "            --beam_search \\\n",
    "            --max_data_loader_n_workers=2 \\\n",
    "            --batch_size=8 \\\n",
    "            --min_length={caption_min} \\\n",
    "            --max_length={caption_max} \\\n",
    "            --caption_extension=.txt\n",
    "\n",
    "        if not get_ipython().__dict__[\"user_ns\"][\"_exit_code\"]:\n",
    "            import random\n",
    "\n",
    "            captions = [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]\n",
    "            sample = []\n",
    "            for txt in random.sample(captions, min(10, len(captions))):\n",
    "                with open(os.path.join(images_folder, txt), \"r\") as f:\n",
    "                    sample.append(f.read())\n",
    "\n",
    "            os.chdir(root_dir)\n",
    "            # %env PYTHONPATH=/env/python\n",
    "            # clear_output()\n",
    "            print(\n",
    "                f\"üìä Captioning complete. Here are {len(sample)} example captions from your dataset:\"\n",
    "            )\n",
    "            print(\"\".join(sample))\n",
    "\n",
    "proceed4_btn.on_click(proceed_step_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cellView": "form",
    "id": "WBFik7accyDz"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eadcce0bcd2d4c599aa5fa3d4d3b2f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h2>5Ô∏è‚É£ Curate your tags</h2>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e275105c09dc441cb3cae0d4609771b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value=\"Modify your dataset's tags. You can run this cell multiple times with different parameters.\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5a3d3ef18549159ff517e4b7ba0d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Put an activation tag at the start of every text file. This is useful to make learning better and‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e0184847854eeaa29f9ad0aaf1f7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Common tags that are removed such as hair color, etc. will be \"absorbed\" by your activation tag.'‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c34b15bc3e240eeaabd58e12382d5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Global activation tag:', placeholder='hatsune miku')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6603ea1c10a4bbaa860a6ba6b2bd2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Remove tags:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0d1e02811e4b529508796d747287a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d869d220328848978f879a5ac228c246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='In this advanced section, you can search text files containing matching tags, and replace them wi‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c984bb8acbbf4eddbd6a4868e6a3c9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Search tags:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76aaf39936394d1e97c0fbe527bd449c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Replace with:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60446a4d179145ac8316a112f1400061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Search Mode', options=('OR', 'AND'), value='OR')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e401a8c8a5004e6f8e5b2df4287d0d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='New becomes activation tag:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf281f701dc4905a6e83d686cb6c802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='These may be useful sometimes. Will remove existing activation tags, be careful.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a84586e2f304b189593d8f5ba4a1cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Sort alphabetically:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3ef1f5dd9442429cf42a933f50713f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Remove duplicates:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44858fd03b094e0eaca5a3485aff9828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Proceed', icon='check', style=ButtonStyle(), tooltip='Proceed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_activation_tag_widget = widgets.Text(\n",
    "    placeholder=\"hatsune miku\",\n",
    "    description='Global activation tag:',\n",
    ")\n",
    "\n",
    "remove_tags_widget = widgets.Text(\n",
    "    description='Remove tags:',\n",
    ")\n",
    "\n",
    "search_tags_widget = widgets.Text(\n",
    "    description='Search tags:'\n",
    ")\n",
    "\n",
    "replace_with_widget = widgets.Text(\n",
    "    description='Replace with:'\n",
    ")\n",
    "\n",
    "search_mode_widget = widgets.Dropdown(\n",
    "    description='Search Mode',\n",
    "    options=[\"OR\", \"AND\"],\n",
    "    value='OR'\n",
    ")\n",
    "\n",
    "new_becomes_activation_tag_widget = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='New becomes activation tag:',\n",
    ")\n",
    "\n",
    "sort_alphabetically_widget = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Sort alphabetically:',\n",
    ")\n",
    "\n",
    "remove_duplicates_widget = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Remove duplicates:',\n",
    ")\n",
    "\n",
    "proceed5_btn = widgets.Button(\n",
    "    description=\"Proceed\",\n",
    "    disabled=False,\n",
    "    button_style=\"\",  # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip=\"Proceed\",\n",
    "    icon=\"check\",  # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "display(\n",
    "    widgets.HTML('''<h2>5Ô∏è‚É£ Curate your tags</h2>'''),\n",
    "    widgets.Label(\"Modify your dataset's tags. You can run this cell multiple times with different parameters.\"),\n",
    "    widgets.Label(\"Put an activation tag at the start of every text file. This is useful to make learning better and activate your Lora easier. Set `keep_tokens` to 1 when training.<p>\"),\n",
    "    widgets.Label('Common tags that are removed such as hair color, etc. will be \"absorbed\" by your activation tag.'),\n",
    "    global_activation_tag_widget,\n",
    "    remove_tags_widget,\n",
    "    widgets.Label(),\n",
    "    widgets.Label(\"In this advanced section, you can search text files containing matching tags, and replace them with less/more/different tags. If you select the checkbox below, any extra tags will be put at the start of the file, letting you assign different activation tags to different parts of your dataset. Still, you may want a more advanced tool for this.\"),\n",
    "    search_tags_widget,\n",
    "    replace_with_widget,\n",
    "    search_mode_widget,\n",
    "    new_becomes_activation_tag_widget,\n",
    "    widgets.Label(\"These may be useful sometimes. Will remove existing activation tags, be careful.\"),\n",
    "    sort_alphabetically_widget,\n",
    "    remove_duplicates_widget,\n",
    "    proceed5_btn\n",
    ")\n",
    "\n",
    "def proceed_step_5(b):\n",
    "    if \"step1_installed_flag\" not in globals():\n",
    "        raise Exception(\"Please run step 1 first!\")\n",
    "    \n",
    "    global_activation_tag = global_activation_tag_widget.value\n",
    "    remove_tags = remove_tags_widget.value\n",
    "   \n",
    "    search_tags = search_tags_widget.value\n",
    "    replace_with = replace_with_widget.value\n",
    "    search_mode = search_mode_widget.value\n",
    "    new_becomes_activation_tag = new_becomes_activation_tag_widget.value\n",
    "    \n",
    "    sort_alphabetically = sort_alphabetically_widget.value\n",
    "    remove_duplicates = remove_duplicates_widget.value\n",
    "\n",
    "    def split_tags(tagstr):\n",
    "        return [s.strip() for s in tagstr.split(\",\") if s.strip()]\n",
    "\n",
    "    activation_tag_list = split_tags(global_activation_tag)\n",
    "    remove_tags_list = split_tags(remove_tags)\n",
    "    search_tags_list = split_tags(search_tags)\n",
    "    replace_with_list = split_tags(replace_with)\n",
    "    replace_new_list = [t for t in replace_with_list if t not in search_tags_list]\n",
    "\n",
    "    replace_with_list = [t for t in replace_with_list if t not in replace_new_list]\n",
    "    replace_new_list.reverse()\n",
    "    activation_tag_list.reverse()\n",
    "\n",
    "    remove_count = 0\n",
    "    replace_count = 0\n",
    "\n",
    "    for txt in [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]:\n",
    "\n",
    "        with open(os.path.join(images_folder, txt), \"r\") as f:\n",
    "            tags = [s.strip() for s in f.read().split(\",\")]\n",
    "\n",
    "        if remove_duplicates:\n",
    "            tags = list(set(tags))\n",
    "        if sort_alphabetically:\n",
    "            tags.sort()\n",
    "\n",
    "        for rem in remove_tags_list:\n",
    "            if rem in tags:\n",
    "                remove_count += 1\n",
    "                tags.remove(rem)\n",
    "\n",
    "        if (\n",
    "            \"AND\" in search_mode\n",
    "            and all(r in tags for r in search_tags_list)\n",
    "            or \"OR\" in search_mode\n",
    "            and any(r in tags for r in search_tags_list)\n",
    "        ):\n",
    "            replace_count += 1\n",
    "            for rem in search_tags_list:\n",
    "                if rem in tags:\n",
    "                    tags.remove(rem)\n",
    "            for add in replace_with_list:\n",
    "                if add not in tags:\n",
    "                    tags.append(add)\n",
    "            for new in replace_new_list:\n",
    "                if new_becomes_activation_tag:\n",
    "                    if new in tags:\n",
    "                        tags.remove(new)\n",
    "                    tags.insert(0, new)\n",
    "                else:\n",
    "                    if new not in tags:\n",
    "                        tags.append(new)\n",
    "\n",
    "        for act in activation_tag_list:\n",
    "            if act in tags:\n",
    "                tags.remove(act)\n",
    "            tags.insert(0, act)\n",
    "\n",
    "        with open(os.path.join(images_folder, txt), \"w\") as f:\n",
    "            f.write(\", \".join(tags))\n",
    "\n",
    "    if global_activation_tag:\n",
    "        print(f\"\\nüìé Applied new activation tag(s): {', '.join(activation_tag_list)}\")\n",
    "    if remove_tags:\n",
    "        print(f\"\\nüöÆ Removed {remove_count} tags.\")\n",
    "    if search_tags:\n",
    "        print(f\"\\nüí´ Replaced in {replace_count} files.\")\n",
    "    print(\"\\n‚úÖ Done! Check your updated tags in the Extras below.\")\n",
    "\n",
    "proceed5_btn.on_click(proceed_step_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cellView": "form",
    "id": "HuJB7BGAyZCw"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ü¶Ä [Click here to open the Lora trainer](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@markdown ### 6Ô∏è‚É£ Ready\n",
    "#@markdown You should be ready to [train your Lora](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb)!\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(f\"### ü¶Ä [Click here to open the Lora trainer](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb)\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDB9GXRONfiU"
   },
   "source": [
    "## *Ô∏è‚É£ Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cellView": "form",
    "id": "xEsqOglcc6hA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Top 50 tags:\n"
     ]
    }
   ],
   "source": [
    "if \"step1_installed_flag\" not in globals():\n",
    "  raise Exception(\"Please run step 1 first!\")\n",
    "  \n",
    "#@markdown ### üìà Analyze Tags\n",
    "#@markdown Perhaps you need another look at your dataset.\n",
    "show_top_tags = 50 #@param {type:\"number\"}\n",
    "\n",
    "from collections import Counter\n",
    "top_tags = Counter()\n",
    "\n",
    "for txt in [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]:\n",
    "  with open(os.path.join(images_folder, txt), 'r') as f:\n",
    "    top_tags.update([s.strip() for s in f.read().split(\",\")])\n",
    "\n",
    "top_tags = Counter(top_tags)\n",
    "print(f\"üìä Top {show_top_tags} tags:\")\n",
    "for k, v in top_tags.most_common(show_top_tags):\n",
    "  print(f\"{k} ({v})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cellView": "form",
    "id": "x56xQYwuOz2V"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m     10\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìÇ Connecting to Google Drive...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m   drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#@markdown ### üìÇ Unzip dataset\n",
    "#@markdown It's much slower to upload individual files to your Drive, so you may want to upload a zip if you have your dataset in your computer.\n",
    "zip = \"/content/drive/MyDrive/Loras/example.zip\" #@param {type:\"string\"}\n",
    "extract_to = \"/content/drive/MyDrive/Loras/example/dataset\" #@param {type:\"string\"}\n",
    "\n",
    "import os, zipfile\n",
    "\n",
    "if not os.path.exists('/content/drive'):\n",
    "  from google.colab import drive\n",
    "  print(\"üìÇ Connecting to Google Drive...\")\n",
    "  drive.mount('/content/drive')\n",
    "\n",
    "os.makedirs(extract_to, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip, 'r') as f:\n",
    "  f.extractall(extract_to)\n",
    "\n",
    "print(\"‚úÖ Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "dLetTcLVOvAE"
   },
   "outputs": [],
   "source": [
    "#@markdown ### üî¢ Count datasets\n",
    "#@markdown Google Drive makes it impossible to count the files in a folder, so this will show you the file counts in all folders and subfolders.\n",
    "folder = \"/content/drive/MyDrive/Loras\" #@param {type:\"string\"}\n",
    "\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "if not os.path.exists('/content/drive'):\n",
    "    print(\"üìÇ Connecting to Google Drive...\\n\")\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "tree = {}\n",
    "exclude = (\"_logs\", \"/output\")\n",
    "for i, (root, dirs, files) in enumerate(os.walk(folder, topdown=True)):\n",
    "  dirs[:] = [d for d in dirs if all(ex not in d for ex in exclude)]\n",
    "  images = len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
    "  captions = len([f for f in files if f.lower().endswith(\".txt\")])\n",
    "  others = len(files) - images - captions\n",
    "  path = root[folder.rfind(\"/\")+1:]\n",
    "  tree[path] = None if not images else f\"{images:>4} images | {captions:>4} captions |\"\n",
    "  if tree[path] and others:\n",
    "    tree[path] += f\" {others:>4} other files\"\n",
    "\n",
    "pad = max(len(k) for k in tree)\n",
    "print(\"\\n\".join(f\"üìÅ{k.ljust(pad)} | {v}\" for k, v in tree.items() if v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"step1_installed_flag\" not in globals():\n",
    "  raise Exception(\"Please run step 1 first!\")\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "#@markdown ### üñºÔ∏è Reduce dataset filesize\n",
    "#@markdown This will convert all images in the project folder to jpeg, reducing filesize without affecting quality too much. This can also solve some errors.\n",
    "location = images_folder\n",
    "\n",
    "for dir in [d[0] for d in os.walk(location)]:\n",
    "    os.chdir(dir)\n",
    "    converted = False\n",
    "    for file_name in list(os.listdir(\".\")):\n",
    "        try:\n",
    "            # Convert png to jpeg\n",
    "            if file_name.endswith(\".png\"):\n",
    "                if not converted:\n",
    "                    print(f\"Converting {dir}\")\n",
    "                    converted = True\n",
    "                im = Image.open(file_name)\n",
    "                im = im.convert(\"RGB\")\n",
    "                new_file_name = os.path.splitext(file_name)[0] + \".jpeg\"\n",
    "                im.save(new_file_name, quality=95)\n",
    "                os.remove(file_name)\n",
    "                file_name = new_file_name\n",
    "            # Resize large jpegs\n",
    "            if file_name.endswith((\".jpeg\", \".jpg\")) and os.path.getsize(file_name) > 2000000:\n",
    "                if not converted:\n",
    "                    print(f\"Converting {dir}\")\n",
    "                    converted = True\n",
    "                im = Image.open(file_name)\n",
    "                im = im.resize((int(im.width/2), int(im.height/2)))\n",
    "                im.save(file_name, quality=95)\n",
    "            # Rename jpg to jpeg\n",
    "            if file_name.endswith(\".jpg\"):\n",
    "                if not converted:\n",
    "                    print(f\"Converting {dir}\")\n",
    "                new_file_name = os.path.splitext(file_name)[0] + \".jpeg\"\n",
    "                os.rename(file_name, new_file_name)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {file_name}: {e}\")\n",
    "    if converted:\n",
    "        print(f\"Converted {dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "y6PKW-LIr214"
   },
   "outputs": [],
   "source": [
    "if \"step1_installed_flag\" not in globals():\n",
    "  raise Exception(\"Please run step 1 first!\")\n",
    "  \n",
    "#@markdown ### üöÆ Clean folder\n",
    "#@markdown Careful! Deletes all non-image files in the project folder.\n",
    "\n",
    "!find {images_folder} -type f ! \\( -name '*.png' -o -name '*.jpg' -o -name '*.jpeg' \\) -delete\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
